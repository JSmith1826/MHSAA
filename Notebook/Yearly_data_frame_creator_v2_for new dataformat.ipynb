{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## THIS BOOK IS TO CREATE THE YEARSLY STATS USING DATA FROM THE NEW EXTRACTION TECHNIQUE ########\n",
    "########## HOPEFULLY WILL BE ABLE TO COME UP WITH A FUNCTION THAT WORKS FOR MOST DIFFERENT SPORTS TYPES ##########\n",
    "\n",
    "# WANT FINAL DATA TO BE VERY SIMALR TO THE DATA TABLES CREATED BY THE OLD FUNCTION THAT \n",
    "### USED THE RECORD BY RECORD PARSING METHOD\n",
    "\n",
    "### THIS WILL USE THE DATA THAT IS BROUGH DOWN FOR AN ENTIRE SEASON WITH A SINGLE ROW FOR EVERY GAME\n",
    "### WILL NEED TO FIND A STRATEGY TO REATE AGG STATS FOR HOME AND AWAY RESULTS AND STATS\n",
    "## OLD METHOD USED DATA WHERE EACH GAME HAD 2 ROWS, ONE FROM THE HOME TEAM PERSPECTIVE AND ONE FROM THE AWAY TEAM PERSPECTIVE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies and Setup\n",
    "## Dependencies and Setup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n"
     ]
    }
   ],
   "source": [
    "### URL BLOCK ###\n",
    "\n",
    "# # example url for softball\n",
    "\n",
    "# eaxmple_url = 'https://my.mhsaa.com/DesktopModules/MHSAA-Endpoint/handlers/ContestWithParticipantDepotSearch.ashx?Method=ScoreCenterSearch&StartDate=2023-01-26&EndDate=2023-06-26&Sport=GSB&Level=V'\n",
    "\n",
    "\n",
    "## static peices of the url\n",
    "\n",
    "url_a = 'https://my.mhsaa.com/DesktopModules/MHSAA-Endpoint/handlers/ContestWithParticipantDepotSearch.ashx?Method=ScoreCenterSearch&StartDate='\n",
    "\n",
    "# length of url_a\n",
    "print(len(url_a))\n",
    "\n",
    "url_b = '&EndDate='\n",
    "url_c = '&Sport='\n",
    "url_d = '&Level=V'\n",
    "\n",
    "\n",
    "### Date format ###\n",
    "# YYYY-MM-DD\n",
    "\n",
    "## academic year start and end dates\n",
    "# Start August 1st\n",
    "# End July 31st\n",
    "\n",
    "# example date\n",
    "# 2023-01-26\n",
    "\n",
    "\n",
    "### Sport codes ###\n",
    "\n",
    "# Ice Hockey (Boys) = BIH\n",
    "# Football = BFB\n",
    "# Baseball = BBA\n",
    "# Softball = GSB\n",
    "\n",
    "# Boys Basket Ball = BBB\n",
    "# Girls Basket Ball = GBB\n",
    "\n",
    "# Lacrosse (Boys) = BBL\n",
    "# Lacrosse (Girls) = GGL\n",
    "# Soccer (Boys) = BSO\n",
    "# Soccer (Girls) = GSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = df_all\n",
    "\n",
    "#################### BRING ALL THE CODE FROM EXTRACT DATA SPORT WORKBOOK INTO SINGLE FUNCTION ####################\n",
    "\n",
    "## Define close and blowout games\n",
    "def get_game_situation(row):\n",
    "    sport = row['SportCode']  # Assuming the sport name is in the format 'BSO - Baseball'\n",
    "    score_diff = abs(row['HostScore'] - row['AwayScore'])\n",
    "\n",
    "    # Check if either score is None or NaN. If so, return 'Unknown'\n",
    "    if pd.isnull(row['HostScore']) or pd.isnull(row['AwayScore']):\n",
    "        return 'Unknown'\n",
    "    \n",
    "    if score_diff <= score_threasolds[sport]['close']:\n",
    "        return 'Close'\n",
    "    elif score_diff >= score_threasolds[sport]['blowout']:\n",
    "        return 'Blowout'\n",
    "    else:\n",
    "        return 'Normal'\n",
    "\n",
    "############ GAME LEVEL PREPROSSING ############\n",
    "\n",
    "###### SIMPLE FUNCTIONS FROM THE PREVIOUS NOTEBOOKS ######\n",
    "\n",
    "# construct the url for a given year\n",
    "def url_construct(year):\n",
    "    # Create start and end dates in teh YYYY-MM-DD format\n",
    "    # Request one academic year of data at a time August 1st to July 31st\n",
    "    start_date = str(year) + '-08-01'\n",
    "    end_date = str(year + 1) + '-07-31'\n",
    "    url = url_a + start_date + url_b + end_date + url_c + sport_code + url_d\n",
    "    return url\n",
    "\n",
    "# extrtact academic year from date\n",
    "def get_year(date):\n",
    "    return date[:4]\n",
    "\n",
    "\n",
    "# If tournament name contains Regional, then regional; if quarterfinal, then quarterfinal, ect\n",
    "def get_postseason_level(tournament_name):\n",
    "    if tournament_name is not None:\n",
    "        if \"District\" in tournament_name:\n",
    "            return 'District'\n",
    "        elif 'Regional' in tournament_name:\n",
    "            return 'Regional'\n",
    "        elif 'Quarter Final' in tournament_name:\n",
    "            return 'Quarterfinal'\n",
    "        elif 'Semifinal' in tournament_name:\n",
    "            return 'Semifinal'\n",
    "        elif 'Final' in tournament_name:\n",
    "            return 'Final'\n",
    "    # if not postseason, return none\n",
    "    return None\n",
    "\n",
    "############ START TO PROCESS THE DATA ############\n",
    "######## SHAPES DF BY DROPPING AND RENAMING COLUMNS ########\n",
    "#######  ADDS COULMN FOR SPORT NAME, YEAR, OT INFO AND FORIET INFO ########\n",
    "def preprocess(df):\n",
    "\n",
    "    # Creating ScoreNotes column\n",
    "    df['ScoreNotes'] = None\n",
    "    df.loc[df['Score'].str.contains('Forfeit'), 'ScoreNotes'] = 'Forfeit'\n",
    "    df.loc[df['Score'].str.contains('Forfeit'), ['HostScore', 'AwayScore']] = 0\n",
    "\n",
    "    # Creating and cleaning up OT column\n",
    "    df['OT'] = df['Score'].str.extract(r'(\\(.*\\))') # extract anything surrounded by parentheses\n",
    "    df['OT'] = df['OT'].str.replace('(', '')\n",
    "    df['OT'] = df['OT'].str.replace(')', '')\n",
    "\n",
    "    # Dropping the Score column\n",
    "    df = df.drop(columns=['Score'])\n",
    "\n",
    "    # Assuming that the rest of the columns are already correctly named, if not, you can rename them as follows\n",
    "    df.rename(columns={\n",
    "        'Season_Year': 'SeasonYear',\n",
    "        'SportGenderDesc': 'SportName',\n",
    "        'StartDate': 'StartDate',\n",
    "        'IsPostSeason': 'IsPostSeason',\n",
    "        'Notes': 'Notes',\n",
    "        'HostSchoolId': 'HostSchoolId',\n",
    "        'HostScore': 'HostScore',\n",
    "        'HostTeamName': 'HostTeamName',\n",
    "        'AwaySchoolId': 'AwaySchoolId',\n",
    "        'AwayScore': 'AwayScore',\n",
    "        'AwayTeamName': 'AwayTeamName',\n",
    "        'ContestName': 'ContestNotes',\n",
    "        'TournamentName': 'TournamentName',\n",
    "        'TournamentNumber': 'TournamentNumber',\n",
    "    }, inplace=True)\n",
    "\n",
    "    df['PostSeasonLevel'] = df['TournamentName'].apply(get_postseason_level)\n",
    "            # add sport code column\n",
    "    \n",
    "\n",
    "    df = df[['SeasonYear', 'SportName', 'StartDate', 'IsPostSeason', 'Notes', \n",
    "            'OT', 'ScoreNotes',\n",
    "            'HostSchoolId', 'HostScore', 'HostTeamName', \n",
    "            'AwaySchoolId', 'AwayScore', 'AwayTeamName', \n",
    "            'ContestNotes',  \n",
    "            'PostSeasonLevel','TournamentNumber']]\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "## Send the data to the preprocess function\n",
    "# df = preprocess(df)\n",
    "\n",
    "\n",
    "############ Add further processing to the data ############\n",
    "\n",
    "def yearly_stats(df):\n",
    "    # drop any forfieted games (score = 0)\n",
    "    df = df.loc[(df['HostScore'] != 0) & (df['AwayScore'] != 0)]\n",
    "\n",
    "    #### Drop null scores\n",
    "    df = df.dropna(subset=['HostScore', 'AwayScore'])\n",
    "    ## scores to int\n",
    "    df['HostScore'] = df['HostScore'].astype(int)\n",
    "    df['AwayScore'] = df['AwayScore'].astype(int)\n",
    "\n",
    "\n",
    "    # Create new columns holding the result for the home and away teams\n",
    "    df['HostResult'] = np.where(df['HostScore'] > df['AwayScore'], 'W', \n",
    "                                np.where(df['HostScore'] < df['AwayScore'], 'L', \n",
    "                                        np.where(df['HostScore'] == df['AwayScore'], 'T', None)))\n",
    "\n",
    "    df['AwayResult'] = np.where(df['HostScore'] > df['AwayScore'], 'L', \n",
    "                                np.where(df['HostScore'] < df['AwayScore'], 'W', \n",
    "                                        np.where(df['HostScore'] == df['AwayScore'], 'T', None)))\n",
    "    # Return the dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ### Append all the dataframes together and save to a new csv\n",
    "# df_all = pd.DataFrame()\n",
    "# for df, name in dataframes:\n",
    "#     df_all = df_all.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a loop that goes through each sport and each year and creates a url to pull data from\n",
    "# there will be empty responses for some of the years and sports so will need to create a way to deal with that\n",
    "\n",
    "# create an empty list to store the urls\n",
    "url_list = []\n",
    "\n",
    "\n",
    "## create a list of the sports to be used in the url\n",
    "sport_list = ['BBA','BIH', 'BFB', 'BSB', 'GSB', 'BBB', 'GBB', 'BBL', 'GGL', 'BSO', 'GSO']\n",
    "\n",
    "# define the years to parse\n",
    "year_list = list(range(2023, 2024))\n",
    "\n",
    "# create a loop that goes through each sport and each academic year and creates a url to pull data from\n",
    "# academic year is defined as starting on August 1st and ending on July 31st\n",
    "for sport in tqdm.tqdm(sport_list):\n",
    "    for year in year_list:\n",
    "        # create the start and end dates for the url\n",
    "        start_date = str(year) + '-08-01'\n",
    "        end_date = str(year + 1) + '-07-31'\n",
    "        # create the url\n",
    "        url = url_a + start_date + url_b + end_date + url_c + sport + url_d\n",
    "        \n",
    "        url_list.append(url)\n",
    "\n",
    "# check the length of the url list\n",
    "len(url_list)\n",
    "\n",
    "\n",
    "########### TEST BLOCK ############\n",
    "## reduce url list to 10 urls to test the code\n",
    "# url_list = url_list[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4/11 [00:14<00:21,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request to https://my.mhsaa.com/DesktopModules/MHSAA-Endpoint/handlers/ContestWithParticipantDepotSearch.ashx?Method=ScoreCenterSearch&StartDate=2023-08-01&EndDate=2024-07-31&Sport=BSB&Level=V failed with error 'Score'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:44<00:00,  4.01s/it]\n",
      "C:\\Users\\jbanc\\AppData\\Local\\Temp\\ipykernel_17904\\1881103138.py:43: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  master_df = pd.concat(df_list, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "############## BLOCK TO RUN SCRAPE PARSE ##################\n",
    "\n",
    "\n",
    "# Create empty dataframe to store results\n",
    "master_df = pd.DataFrame()\n",
    "\n",
    "response_list = []\n",
    "# Create a list to store the dataframes\n",
    "df_list = []\n",
    "\n",
    "for url in tqdm.tqdm(url_list):\n",
    "    try:\n",
    "        response = requests.get(url).json()\n",
    "        response_list.append(response)\n",
    "\n",
    "        df = pd.DataFrame(response)\n",
    "\n",
    "        # Find the start of the 'ScoreCenterSearch&StartDate=' string in the url\n",
    "        start_index = url.find('ScoreCenterSearch&StartDate=') + len('ScoreCenterSearch&StartDate=')\n",
    "\n",
    "        # The next four characters are the year\n",
    "        year = url[start_index:start_index+4]\n",
    "\n",
    "        # The sport code is the value after '&Sport=' in the url\n",
    "        sport_start_index = url.find('&Sport=') + len('&Sport=')\n",
    "        sport_end_index = url.find('&', sport_start_index)\n",
    "        sport = url[sport_start_index:sport_end_index]\n",
    "\n",
    "        df['SportCode'] = sport\n",
    "        df['SeasonYear'] = year\n",
    "\n",
    "        df_pre = preprocess(df)\n",
    "        df = yearly_stats(df_pre)\n",
    "\n",
    "        # Append the dataframe to the list\n",
    "        df_list.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Request to {url} failed with error {e}\")\n",
    "        response_list.append('no response')\n",
    "\n",
    "# Concatenate all dataframes in the list\n",
    "master_df = pd.concat(df_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33191 entries, 0 to 33190\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   SeasonYear        33191 non-null  object \n",
      " 1   SportName         33191 non-null  object \n",
      " 2   StartDate         33191 non-null  object \n",
      " 3   IsPostSeason      33191 non-null  bool   \n",
      " 4   Notes             9702 non-null   object \n",
      " 5   OT                2936 non-null   object \n",
      " 6   ScoreNotes        0 non-null      object \n",
      " 7   HostSchoolId      33191 non-null  int64  \n",
      " 8   HostScore         33191 non-null  int32  \n",
      " 9   HostTeamName      33191 non-null  object \n",
      " 10  AwaySchoolId      33191 non-null  int64  \n",
      " 11  AwayScore         33191 non-null  int32  \n",
      " 12  AwayTeamName      33191 non-null  object \n",
      " 13  ContestNotes      13123 non-null  object \n",
      " 14  PostSeasonLevel   2150 non-null   object \n",
      " 15  TournamentNumber  2182 non-null   float64\n",
      " 16  HostResult        33191 non-null  object \n",
      " 17  AwayResult        33191 non-null  object \n",
      "dtypes: bool(1), float64(1), int32(2), int64(2), object(12)\n",
      "memory usage: 4.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SeasonYear\n",
       "2023    33191\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.info()\n",
    "\n",
    "## ## value counts for each sport and year\n",
    "master_df.groupby(['SeasonYear']).size()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save master_df for review\n",
    "\n",
    "master_df.to_csv(f'../data/game_level/all_sport_parse_2023_v3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "### Load data so I can skip the parse step\n",
    "# master_df = pd.read_csv(f'../data/game_level/full_parse_all_sport_6_28_v2')\n",
    "## SportName value\n",
    "# master_df['SportName'].value_counts()\n",
    "# master_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a column for ScoreCode based on the SportName\n",
    "\n",
    "# create a dictionary to map the sport name to the score code\n",
    "sport_dict = {'Baseball': 'BBA', \n",
    "            'Basketball (Boys)': 'BBB', \n",
    "            'Basketball (Girls)': 'GBB',\n",
    "            'Soccer (Boys)': 'BSO',\n",
    "            'Soccer (Girls)': 'GSO',\n",
    "            'Football': 'BFB',\n",
    "            'Softball': 'GSB',\n",
    "            'Lacrosse (Boys)': 'BBL',\n",
    "            'Lacrosse (Girls)': 'GGL',          \n",
    "            'Ice Hockey': 'BIH'\n",
    "            }\n",
    "\n",
    "# map the sport name to the sport code and add to the dataframe\n",
    "master_df['SportCode'] = master_df['SportName'].map(sport_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### rENAME MASTER_DF TO DF\n",
    "df = master_df\n",
    "\n",
    "df.columns\n",
    "\n",
    "## sport code value counts\n",
    "df['SportCode'].value_counts()\n",
    "\n",
    "## Create a new column for subcategory of post season \n",
    "# Districts, Regional, State\n",
    "def assign_postseason_sublevel(row):\n",
    "    if row == 'District':\n",
    "        return 'District'\n",
    "    elif row == 'Regional':\n",
    "        return 'Regional'\n",
    "    elif row in ['Final', 'Semifinal', 'Quarterfinal']:\n",
    "        return 'State'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['PostSeasonSubLevel'] = df['PostSeasonLevel'].apply(assign_postseason_sublevel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### NEW CODE BLOCK ############################\n",
    "########### THIS BLOCK DEFINES FUNCTIONS USED TO TURN GAME LEVEL DATA INTO SUMMARRY STATS #######################\n",
    "\n",
    "### \n",
    "# Create a new column for SeasonType\n",
    "df['SeasonType'] = df['IsPostSeason'].apply(lambda x: 'Postseason' if x else 'Regular Season')\n",
    "\n",
    "## Dictionary to hold the score thresholds for each sport\n",
    "score_thresholds = {\n",
    "    'BIH': {\"close\": 1, \"blowout\": 5},\n",
    "    'BFB': {\"close\": 7, \"blowout\": 21},\n",
    "    'BBA': {\"close\": 3, \"blowout\": 8},\n",
    "    'GSB': {\"close\": 3, \"blowout\": 8},\n",
    "    'BBB': {\"close\": 3, \"blowout\": 15},\n",
    "    'GBB': {\"close\": 3, \"blowout\": 15},\n",
    "    'BBL': {\"close\": 2, \"blowout\": 8},\n",
    "    'GGL': {\"close\": 2, \"blowout\": 8},\n",
    "    'BSO': {\"close\": 1, \"blowout\": 5},\n",
    "    'GSO': {\"close\": 1, \"blowout\": 5},\n",
    "}\n",
    "\n",
    "## Determin game type (Close vs Blowout)\n",
    "def get_game_type(row):\n",
    "    threshold = score_thresholds[row['SportCode']]\n",
    "    diff = abs(row['HostScore'] - row['AwayScore'])\n",
    "    if diff <= threshold['close']:\n",
    "        return 'Close'\n",
    "    elif diff >= threshold['blowout']:\n",
    "        return 'Blowout'\n",
    "    else:\n",
    "        return 'Normal'\n",
    "## Apply the function to the dataframe\n",
    "df['GameType'] = df.apply(get_game_type, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SeasonYear', 'SportName', 'StartDate', 'IsPostSeason', 'Notes', 'OT',\n",
       "       'ScoreNotes', 'HostSchoolId', 'HostScore', 'HostTeamName',\n",
       "       'AwaySchoolId', 'AwayScore', 'AwayTeamName', 'ContestNotes',\n",
       "       'PostSeasonLevel', 'TournamentNumber', 'HostResult', 'AwayResult',\n",
       "       'SportCode', 'PostSeasonSubLevel', 'SeasonType', 'GameType'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COPY, flip and amend the DF so I can group by team name in the next block of code\n",
    "\n",
    "# Duplicate the dataframe, swapping host and away team names and scores\n",
    "df_flipped = df.copy()\n",
    "df_flipped['TeamName'] = df['AwayTeamName']\n",
    "df_flipped['OpponentName'] = df['HostTeamName']\n",
    "df_flipped['TeamScore'] = df['AwayScore']\n",
    "df_flipped['OpponentScore'] = df['HostScore']\n",
    "df_flipped['Result'] = df['HostResult'].map({'W': 'L', 'L': 'W', 'T': 'T'})\n",
    "\n",
    "# Append the flipped dataframe to the original dataframe\n",
    "df['TeamName'] = df['HostTeamName']\n",
    "df['OpponentName'] = df['AwayTeamName']\n",
    "df['TeamScore'] = df['HostScore']\n",
    "df['OpponentScore'] = df['AwayScore']\n",
    "df['Result'] = df['HostResult']\n",
    "df = pd.concat([df, df_flipped])\n",
    "\n",
    "# Now you can group by 'TeamName' and calculate the aggregates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SeasonYear', 'SportName', 'StartDate', 'IsPostSeason', 'Notes', 'OT',\n",
       "       'ScoreNotes', 'HostSchoolId', 'HostScore', 'HostTeamName',\n",
       "       'AwaySchoolId', 'AwayScore', 'AwayTeamName', 'ContestNotes',\n",
       "       'PostSeasonLevel', 'TournamentNumber', 'HostResult', 'AwayResult',\n",
       "       'SportCode', 'PostSeasonSubLevel', 'SeasonType', 'GameType', 'TeamName',\n",
       "       'OpponentName', 'TeamScore', 'OpponentScore', 'Result'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbanc\\AppData\\Local\\Temp\\ipykernel_17904\\3803746622.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_regular_season['IsHomeGame'] = df_regular_season['HostTeamName'] == df_regular_season['TeamName']\n"
     ]
    }
   ],
   "source": [
    "## Define the slices of the df that will be used to calculate the aggregatesq\n",
    "\n",
    "# All games for overall stats\n",
    "all_games = df\n",
    "\n",
    "## Regular and Post Season\n",
    "df_postseason = df[df['SeasonType'] == 'Postseason']\n",
    "df_regular_season = df[df['SeasonType'] == 'Regular Season']\n",
    "\n",
    "## Games that went to overtime ['OT'] contains 'OT'\n",
    "## Games that went to overtime ['OT'] contains 'OT'\n",
    "df_overtime = df[df['OT'].str.contains('OT', na=False)]\n",
    "\n",
    "\n",
    "# Close games and blowout games\n",
    "df_close_games = df[df['GameType'] == 'Close']\n",
    "df_blowout_games = df[df['GameType'] == 'Blowout']\n",
    "\n",
    "# District, Regional and state games\n",
    "df_district_games = df[df['PostSeasonSubLevel'] == 'District']\n",
    "df_regional_games = df[df['PostSeasonSubLevel'] == 'Regional']\n",
    "df_state_games = df[df['PostSeasonSubLevel'] == 'State']\n",
    "\n",
    "\n",
    "## Home / Away games (only regular season)\n",
    "df_regular_season['IsHomeGame'] = df_regular_season['HostTeamName'] == df_regular_season['TeamName']\n",
    "df_home_games = df_regular_season[df_regular_season['IsHomeGame'] == True]\n",
    "df_away_games = df_regular_season[df_regular_season['IsHomeGame'] == False]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************\n",
      "Number of rows: 66382\n",
      "Number of unique teams: 1267\n",
      "******************************************\n",
      "Number of rows: 4364\n",
      "Number of unique teams: 720\n",
      "******************************************\n",
      "Number of rows: 62018\n",
      "Number of unique teams: 1267\n",
      "******************************************\n",
      "Number of rows: 1294\n",
      "Number of unique teams: 564\n",
      "******************************************\n",
      "Number of rows: 12658\n",
      "Number of unique teams: 915\n",
      "******************************************\n",
      "Number of rows: 31038\n",
      "Number of unique teams: 1082\n",
      "******************************************\n",
      "Number of rows: 3384\n",
      "Number of unique teams: 720\n",
      "******************************************\n",
      "Number of rows: 754\n",
      "Number of unique teams: 339\n",
      "******************************************\n",
      "Number of rows: 162\n",
      "Number of unique teams: 90\n",
      "******************************************\n",
      "Number of rows: 31009\n",
      "Number of unique teams: 1054\n",
      "******************************************\n",
      "Number of rows: 31009\n",
      "Number of unique teams: 1117\n"
     ]
    }
   ],
   "source": [
    "## cREATE a list of the dataframes that make up the slices of data and print a report about each one\n",
    "\n",
    "df_list = [all_games, df_postseason, df_regular_season, df_overtime, df_close_games, df_blowout_games, df_district_games, df_regional_games, df_state_games, df_home_games, df_away_games]\n",
    "df_names = ['AllGames', 'Postseason', 'RegularSeason', 'Overtime', 'CloseGames', 'BlowoutGames', 'DistrictGames', 'RegionalGames', 'StateGames', 'HomeGames', 'AwayGames']\n",
    "\n",
    "\n",
    "for df in df_list:\n",
    "    print('******************************************')\n",
    "    # print(f'Dataframe: {df_list_names[df_list.index(df)]}')\n",
    "    # print(f'Dataframe Title: {df.title}')\n",
    "    print(f'Number of rows: {len(df)}')\n",
    "    # print(f'Number of columns: {len(df.columns)}')\n",
    "    print(f'Number of unique teams: {len(df.TeamName.unique())}')\n",
    "\n",
    "    ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## NEW BLOCK TO DO THE SUMMARY STATS ######################\n",
    "\n",
    "# calcs each df in the list and adds it to a new list\n",
    "# concatonates the list of dfs into a new df\n",
    "\n",
    "summary_dfs = []  # List to store the summary DataFrames\n",
    "\n",
    "for df, df_name in zip(df_list, df_names):\n",
    "    grouped = df.groupby(['SeasonYear', 'SportCode', 'TeamName'])\n",
    "    summary_df = grouped.agg({\n",
    "        'HostSchoolId': 'count',  # Total games played\n",
    "        'Result': ['count', lambda x: (x == 'W').sum(), lambda x: (x == 'L').sum(), lambda x: (x == 'T').sum()],  # Total wins, losses, and ties\n",
    "        'TeamScore': ['mean', 'sum'],  # Average and total points for\n",
    "        'OpponentScore': ['mean', 'sum'],  # Average and total points against\n",
    "    })\n",
    "\n",
    "    # Rename the columns\n",
    "    summary_df.columns = ['TotalGames', 'ResultTotal', 'Wins', 'Losses', 'Ties', 'AvgPointsFor', 'TotalPointsFor', 'AvgPointsAgainst', 'TotalPointsAgainst']\n",
    "\n",
    "    # Add other statistics\n",
    "    summary_df['WinPct'] = summary_df['Wins'] / summary_df['TotalGames']\n",
    "    summary_df['AvgMargin'] = summary_df['AvgPointsFor'] - summary_df['AvgPointsAgainst']\n",
    "\n",
    "    # Reset the index\n",
    "    summary_df.reset_index(inplace=True)\n",
    "\n",
    "    # Add a new column that indicates the subcategory\n",
    "    summary_df['GameSubcategory'] = df_name\n",
    "\n",
    "    # Add the summary DataFrame to the list\n",
    "    summary_dfs.append(summary_df)\n",
    "\n",
    "# Concatenate all the summary DataFrames together\n",
    "final_summary_df = pd.concat(summary_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeasonYear</th>\n",
       "      <th>SportCode</th>\n",
       "      <th>TeamName</th>\n",
       "      <th>TotalGames</th>\n",
       "      <th>ResultTotal</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Ties</th>\n",
       "      <th>AvgPointsFor</th>\n",
       "      <th>TotalPointsFor</th>\n",
       "      <th>AvgPointsAgainst</th>\n",
       "      <th>TotalPointsAgainst</th>\n",
       "      <th>WinPct</th>\n",
       "      <th>AvgMargin</th>\n",
       "      <th>GameSubcategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2023</td>\n",
       "      <td>BBA</td>\n",
       "      <td>Cedar Springs</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.875000</td>\n",
       "      <td>47</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>36</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>AwayGames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>2023</td>\n",
       "      <td>BSO</td>\n",
       "      <td>Hudsonville</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>DistrictGames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>2023</td>\n",
       "      <td>BFB</td>\n",
       "      <td>Lutheran Westland</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>55</td>\n",
       "      <td>41.600000</td>\n",
       "      <td>208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-30.600000</td>\n",
       "      <td>HomeGames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>2023</td>\n",
       "      <td>BIH</td>\n",
       "      <td>Romeo</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>28</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>26</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>CloseGames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>2023</td>\n",
       "      <td>BIH</td>\n",
       "      <td>Birmingham Groves</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>44</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>BlowoutGames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>2023</td>\n",
       "      <td>BBB</td>\n",
       "      <td>Flint Beecher</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>56.222222</td>\n",
       "      <td>1012</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>990</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>AllGames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4739</th>\n",
       "      <td>2023</td>\n",
       "      <td>GSO</td>\n",
       "      <td>Corunna</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>8</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>51</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-3.583333</td>\n",
       "      <td>AllGames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3892</th>\n",
       "      <td>2023</td>\n",
       "      <td>GBB</td>\n",
       "      <td>Waterford Kettering</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>26.565217</td>\n",
       "      <td>611</td>\n",
       "      <td>44.260870</td>\n",
       "      <td>1018</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>-17.695652</td>\n",
       "      <td>AllGames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>2023</td>\n",
       "      <td>GBB</td>\n",
       "      <td>Auburn Hills Christian</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>14.428571</td>\n",
       "      <td>101</td>\n",
       "      <td>52.857143</td>\n",
       "      <td>370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-38.428571</td>\n",
       "      <td>AllGames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>2023</td>\n",
       "      <td>BFB</td>\n",
       "      <td>North Farmington</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>58</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>56</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>CloseGames</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SeasonYear SportCode                TeamName  TotalGames  ResultTotal  \\\n",
       "97         2023       BBA           Cedar Springs           8            8   \n",
       "1171       2023       BSO             Hudsonville           2            2   \n",
       "1905       2023       BFB       Lutheran Westland           5            5   \n",
       "1963       2023       BIH                   Romeo           8            8   \n",
       "2262       2023       BIH       Birmingham Groves          10           10   \n",
       "955        2023       BBB           Flint Beecher          18           18   \n",
       "4739       2023       GSO                 Corunna          12           12   \n",
       "3892       2023       GBB     Waterford Kettering          23           23   \n",
       "3155       2023       GBB  Auburn Hills Christian           7            7   \n",
       "1696       2023       BFB        North Farmington           2            2   \n",
       "\n",
       "      Wins  Losses  Ties  AvgPointsFor  TotalPointsFor  AvgPointsAgainst  \\\n",
       "97       5       3     0      5.875000              47          4.500000   \n",
       "1171     1       1     0      1.000000               2          0.500000   \n",
       "1905     0       5     0     11.000000              55         41.600000   \n",
       "1963     4       2     2      3.500000              28          3.250000   \n",
       "2262     5       5     0      4.400000              44          4.200000   \n",
       "955     10       8     0     56.222222            1012         55.000000   \n",
       "4739     2      10     0      0.666667               8          4.250000   \n",
       "3892     4      19     0     26.565217             611         44.260870   \n",
       "3155     0       7     0     14.428571             101         52.857143   \n",
       "1696     1       1     0     29.000000              58         28.000000   \n",
       "\n",
       "      TotalPointsAgainst    WinPct  AvgMargin GameSubcategory  \n",
       "97                    36  0.625000   1.375000       AwayGames  \n",
       "1171                   1  0.500000   0.500000   DistrictGames  \n",
       "1905                 208  0.000000 -30.600000       HomeGames  \n",
       "1963                  26  0.500000   0.250000      CloseGames  \n",
       "2262                  42  0.500000   0.200000    BlowoutGames  \n",
       "955                  990  0.555556   1.222222        AllGames  \n",
       "4739                  51  0.166667  -3.583333        AllGames  \n",
       "3892                1018  0.173913 -17.695652        AllGames  \n",
       "3155                 370  0.000000 -38.428571        AllGames  \n",
       "1696                  56  0.500000   1.000000      CloseGames  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Output final summary to csv file\n",
    "\n",
    "final_summary_df.to_csv('../data/all_sports_year_by_year_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ewqfqwefqw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mewqfqwefqw\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ewqfqwefqw' is not defined"
     ]
    }
   ],
   "source": [
    "ewqfqwefqw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(['SeasonYear', 'SportCode', 'SeasonType', 'GameType', 'PostSeasonLevel', 'PostSeasonSubLevel', 'TeamName'])\n",
    "# Now you can group by several columns and calculate the aggregates\n",
    "summary_df = grouped.agg({\n",
    "    'HostSchoolId': 'count',  # Total games played\n",
    "    'Result': ['count', lambda x: (x == 'W').sum(), lambda x: (x == 'L').sum(), lambda x: (x == 'T').sum()],  # Total wins, losses, and ties\n",
    "    'TeamScore': ['mean', 'sum'],  # Average and total points for\n",
    "    'OpponentScore': ['mean', 'sum'],  # Average and total points against\n",
    "})\n",
    "\n",
    "\n",
    "# Rename the columns to your liking\n",
    "summary_df.columns = ['TotalGames', 'ResultTotal', 'Wins', 'Losses', 'Ties', 'AvgPointsFor', 'TotalPointsFor', 'AvgPointsAgainst', 'TotalPointsAgainst']\n",
    "\n",
    "\n",
    "\n",
    "# Add other statistics like win percentage, average margin of victory/defeat, etc.\n",
    "summary_df['WinPct'] = summary_df['Wins'] / summary_df['TotalGames']\n",
    "summary_df['AvgMargin'] = summary_df['AvgPointsFor'] - summary_df['AvgPointsAgainst']\n",
    "\n",
    "# # Reset the index to make 'SeasonYear', 'SportCode', 'SeasonType', and 'GameType' back to columns\n",
    "summary_df.reset_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.sample(20)\n",
    "\n",
    "## SeasonType value counts\n",
    "summary_df['SeasonType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save raw data to csv]\n",
    "# master_df.to_csv(f'../data/TUES_Night_raw.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the slices of the data I want to aggrigate for calculations\n",
    "## Slices will be denoted by creating a new column called SeasonType That will hold the value of the slice (Overall, Regular Season, Postseason, etc.)\n",
    "\n",
    "### Slices - For Each Sport and Each year\n",
    "## all games,\n",
    "## Home and away, \n",
    "## regular season and postseason, \n",
    "## overtime_games, \n",
    "## level of postseason - District / Regional / State\n",
    "## Close games and blowout games - (have a dictionary that defines the threasholds for each sport) \n",
    "score_threasolds = {\n",
    "    'BIH': {\"close\": 1, \"blowout\": 5},\n",
    "    'BFB': {\"close\": 7, \"blowout\": 21},\n",
    "    'BBA': {\"close\": 3, \"blowout\": 8},\n",
    "    'GSB': {\"close\": 3, \"blowout\": 8},\n",
    "    'BBB': {\"close\": 3, \"blowout\": 15},\n",
    "    'GBB': {\"close\": 3, \"blowout\": 15},\n",
    "    'BBL': {\"close\": 2, \"blowout\": 8},\n",
    "    'GGL': {\"close\": 2, \"blowout\": 8},\n",
    "    'BSO': {\"close\": 1, \"blowout\": 5},\n",
    "    'GSO': {\"close\": 1, \"blowout\": 5},\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "## want to calculate the following states for each situation for every year and sport.\n",
    "# I'd also like to create a row that represents the overall stats for each team for each sport\n",
    "# Total games played\n",
    "# Total wins loses and ties\n",
    "# win percentage\n",
    "# average points for\n",
    "# average points against\n",
    "# average margin of victory/defeat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wergwerg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Display master dataframe ########\n",
    "\n",
    "master_df.head()\n",
    "\n",
    "master_df.tail()\n",
    "\n",
    "# master_df.info()\n",
    "\n",
    "# master_df.describe()\n",
    "\n",
    "master_df.columns\n",
    "\n",
    "master_df.shape\n",
    "\n",
    "# master_df.to_csv('master_df_v3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#######  DICTIONARY OF WHAT IS A CLOSE AND BLOWOUT GAME FOR EACH SPORT ############################\n",
    "\n",
    "score_threasolds = {\n",
    "    'BIH': {\"close\": 1, \"blowout\": 5},\n",
    "    'BFB': {\"close\": 7, \"blowout\": 21},\n",
    "    'BB': {\"close\": 3, \"blowout\": 8},\n",
    "    'GSB': {\"close\": 3, \"blowout\": 8},\n",
    "    'BBB': {\"close\": 3, \"blowout\": 15},\n",
    "    'GBB': {\"close\": 3, \"blowout\": 15},\n",
    "    'BBL': {\"close\": 2, \"blowout\": 8},\n",
    "    'GGL': {\"close\": 2, \"blowout\": 8},\n",
    "    'BSO': {\"close\": 1, \"blowout\": 5},\n",
    "    'GSO': {\"close\": 1, \"blowout\": 5},\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Create a new dataframe column for game situation\n",
    "df['GameSituation'] = df.apply(get_game_situation, axis=1)\n",
    "\n",
    "# Seperate close and blowout games\n",
    "close_games = df[df['GameSituation'] == 'Close']\n",
    "blowout_games = df[df['GameSituation'] == 'Blowout']\n",
    "\n",
    "\n",
    "## Define the Slices for Game Situation Catagories\n",
    "\n",
    "# Overall (all regular and post season games)\n",
    "overall = df\n",
    "\n",
    "# Regular Season\n",
    "regular_season = df[df['IsPostSeason'] == False]\n",
    "\n",
    "# Post Season\n",
    "post_season = df[df['IsPostSeason'] == True]\n",
    "# If the scores are 0 drop the row\n",
    "post_season = post_season.drop(post_season[(post_season['HostScore'] == 0) & (post_season['AwayScore'] == 0)].index)\n",
    "\n",
    "# Overtime Games\n",
    "overtime_games = df[df['OT'].notnull()]\n",
    "\n",
    "# Assuming 'PostSeasonLevel' is a column with values like 'District', 'Regional', etc.\n",
    "district_games = df[df['PostSeasonLevel'] == 'District']\n",
    "regional_games = df[df['PostSeasonLevel'] == 'Regional']\n",
    "quarterfinal_games = df[df['PostSeasonLevel'] == 'Quarterfinal']\n",
    "semifinal_games = df[df['PostSeasonLevel'] == 'Semifinal']\n",
    "final_games = df[df['PostSeasonLevel'] == 'Final']\n",
    "\n",
    "### Create new dataframes organized by team of all home games and all away games\n",
    "df_home = regular_season[['SeasonYear', 'SportName', 'StartDate', 'IsPostSeason', 'Notes',\n",
    "        'OT', 'ScoreNotes', 'HostSchoolId', 'HostScore', 'HostTeamName',\n",
    "            'ContestNotes', 'TournamentNumber', 'PostSeasonLevel', 'SportCode',\n",
    "            'AwaySchoolId', 'AwayScore', 'AwayTeamName', 'HostResult']]\n",
    "## Assign 'SeasonType' as 'Home'\n",
    "df_home['SeasonType'] = 'Home'\n",
    "\n",
    "df_away = regular_season[['SeasonYear', 'SportName', 'StartDate', 'IsPostSeason', 'Notes',\n",
    "            'OT', 'ScoreNotes', 'HostSchoolId', 'HostScore', 'HostTeamName',\n",
    "            'ContestNotes', 'TournamentNumber', 'PostSeasonLevel', 'SportCode',\n",
    "            'AwaySchoolId', 'AwayScore', 'AwayTeamName', 'AwayResult']]\n",
    "## Assign 'SeasonType' as 'Away'\n",
    "df_away['SeasonType'] = 'Away'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdfgasdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### see if anything came out of it\n",
    "\n",
    "print(df_all.shape)\n",
    "\n",
    "print(df_all.info())\n",
    "# df_all.sample(10)\n",
    "df_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copied to above\n",
    "\n",
    "\n",
    "\n",
    "# def yearly_stats(df):\n",
    "#     # drop any forfieted games (score = 0)\n",
    "#     df = df.loc[(df['HostScore'] != 0) & (df['AwayScore'] != 0)]\n",
    "\n",
    "#     #### Drop null scores\n",
    "#     df = df.dropna(subset=['HostScore', 'AwayScore'])\n",
    "#     ## scores to int\n",
    "#     df['HostScore'] = df['HostScore'].astype(int)\n",
    "#     df['AwayScore'] = df['AwayScore'].astype(int)\n",
    "\n",
    "\n",
    "#     # Create new columns holding the result for the home and away teams\n",
    "#     df['HostResult'] = np.where(df['HostScore'] > df['AwayScore'], 'W', \n",
    "#                                 np.where(df['HostScore'] < df['AwayScore'], 'L', \n",
    "#                                         np.where(df['HostScore'] == df['AwayScore'], 'T', None)))\n",
    "\n",
    "#     df['AwayResult'] = np.where(df['HostScore'] > df['AwayScore'], 'L', \n",
    "#                                 np.where(df['HostScore'] < df['AwayScore'], 'W', \n",
    "#                                         np.where(df['HostScore'] == df['AwayScore'], 'T', None)))\n",
    "\n",
    "\n",
    "\n",
    "#     #######  DICTIONARY OF WHAT IS A CLOSE AND BLOWOUT GAME FOR EACH SPORT ############################\n",
    "\n",
    "#     score_threasolds = {\n",
    "#         'BIH': {\"close\": 1, \"blowout\": 5},\n",
    "#         'BFB': {\"close\": 7, \"blowout\": 21},\n",
    "#         'BSB': {\"close\": 3, \"blowout\": 8},\n",
    "#         'GSB': {\"close\": 3, \"blowout\": 8},\n",
    "#         'BBB': {\"close\": 3, \"blowout\": 15},\n",
    "#         'GBB': {\"close\": 3, \"blowout\": 15},\n",
    "#         'BBL': {\"close\": 2, \"blowout\": 8},\n",
    "#         'GGL': {\"close\": 2, \"blowout\": 8},\n",
    "#         'BSO': {\"close\": 1, \"blowout\": 5},\n",
    "#         'GSO': {\"close\": 1, \"blowout\": 5},\n",
    "#     }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     ## Create a new dataframe column for game situation\n",
    "#     df['GameSituation'] = df.apply(get_game_situation, axis=1)\n",
    "\n",
    "#     # Seperate close and blowout games\n",
    "#     close_games = df[df['GameSituation'] == 'Close']\n",
    "#     blowout_games = df[df['GameSituation'] == 'Blowout']\n",
    "\n",
    "\n",
    "#     ## Define the Slices for Game Situation Catagories\n",
    "\n",
    "#     # Overall (all regular and post season games)\n",
    "#     overall = df\n",
    "\n",
    "#     # Regular Season\n",
    "#     regular_season = df[df['IsPostSeason'] == False]\n",
    "\n",
    "#     # Post Season\n",
    "#     post_season = df[df['IsPostSeason'] == True]\n",
    "#     # If the scores are 0 drop the row\n",
    "#     post_season = post_season.drop(post_season[(post_season['HostScore'] == 0) & (post_season['AwayScore'] == 0)].index)\n",
    "\n",
    "#     # Overtime Games\n",
    "#     overtime_games = df[df['OT'].notnull()]\n",
    "\n",
    "#     # Assuming 'PostSeasonLevel' is a column with values like 'District', 'Regional', etc.\n",
    "#     district_games = df[df['PostSeasonLevel'] == 'District']\n",
    "#     regional_games = df[df['PostSeasonLevel'] == 'Regional']\n",
    "#     quarterfinal_games = df[df['PostSeasonLevel'] == 'Quarterfinal']\n",
    "#     semifinal_games = df[df['PostSeasonLevel'] == 'Semifinal']\n",
    "#     final_games = df[df['PostSeasonLevel'] == 'Final']\n",
    "\n",
    "#     ### Create new dataframes organized by team of all home games and all away games\n",
    "#     df_home = regular_season[['SeasonYear', 'SportName', 'StartDate', 'IsPostSeason', 'Notes',\n",
    "#             'OT', 'ScoreNotes', 'HostSchoolId', 'HostScore', 'HostTeamName',\n",
    "#                 'ContestNotes', 'TournamentNumber', 'PostSeasonLevel', 'SportCode',\n",
    "#                 'AwaySchoolId', 'AwayScore', 'AwayTeamName', 'HostResult']]\n",
    "#     ## Assign 'SeasonType' as 'Home'\n",
    "#     df_home['SeasonType'] = 'Home'\n",
    "\n",
    "#     df_away = regular_season[['SeasonYear', 'SportName', 'StartDate', 'IsPostSeason', 'Notes',\n",
    "#                 'OT', 'ScoreNotes', 'HostSchoolId', 'HostScore', 'HostTeamName',\n",
    "#                 'ContestNotes', 'TournamentNumber', 'PostSeasonLevel', 'SportCode',\n",
    "#                 'AwaySchoolId', 'AwayScore', 'AwayTeamName', 'AwayResult']]\n",
    "#     ## Assign 'SeasonType' as 'Away'\n",
    "#     df_away['SeasonType'] = 'Away'\n",
    "\n",
    "\n",
    "\n",
    "#     ### Append all the dataframes together and save to a new csv\n",
    "#     df_all = pd.DataFrame()\n",
    "#     for df, name in dataframes:\n",
    "#         df_all = df_all.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Show stats for df_all\n",
    "    print('Overall Stats')\n",
    "    print('Total Games: ', len(df_all))\n",
    "    print('Total Home Wins: ', len(df_all[df_all['HostResult'] == 'W']))\n",
    "    print('Total Home Losses: ', len(df_all[df_all['HostResult'] == 'L']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
